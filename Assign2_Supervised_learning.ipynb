{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f369f0a",
   "metadata": {},
   "source": [
    "\n",
    "# Assignments #2 Supervised Learning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56e82866",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ---- (Run this first) ----\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# import libraries\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#from sklearn.model_selection import train_test_split\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# letting plots appear inline\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmatplotlib\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43minline\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAll Done!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:2504\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2502\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2503\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2504\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2508\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/IPython/core/magics/pylab.py:103\u001b[39m, in \u001b[36mPylabMagics.matplotlib\u001b[39m\u001b[34m(self, line)\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     99\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAvailable matplotlib backends: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m         % _list_matplotlib_backends_and_gui_loops()\n\u001b[32m    101\u001b[39m     )\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     gui, backend = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshell\u001b[49m\u001b[43m.\u001b[49m\u001b[43menable_matplotlib\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m     \u001b[38;5;28mself\u001b[39m._show_matplotlib_backend(args.gui, backend)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3787\u001b[39m, in \u001b[36mInteractiveShell.enable_matplotlib\u001b[39m\u001b[34m(self, gui)\u001b[39m\n\u001b[32m   3784\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib_inline\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend_inline\u001b[39;00m\n\u001b[32m   3786\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIPython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pylabtools \u001b[38;5;28;01mas\u001b[39;00m pt\n\u001b[32m-> \u001b[39m\u001b[32m3787\u001b[39m gui, backend = \u001b[43mpt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_gui_and_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgui\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpylab_gui_select\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gui != \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3790\u001b[39m     \u001b[38;5;66;03m# If we have our first gui selection, store it\u001b[39;00m\n\u001b[32m   3791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pylab_gui_select \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/IPython/core/pylabtools.py:338\u001b[39m, in \u001b[36mfind_gui_and_backend\u001b[39m\u001b[34m(gui, gui_select)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_gui_and_backend\u001b[39m(gui=\u001b[38;5;28;01mNone\u001b[39;00m, gui_select=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    322\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Given a gui string return the gui and mpl backend.\u001b[39;00m\n\u001b[32m    323\u001b[39m \n\u001b[32m    324\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    335\u001b[39m \u001b[33;03m    'WXAgg','Qt4Agg','module://matplotlib_inline.backend_inline','agg').\u001b[39;00m\n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m    340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _matplotlib_manages_backends():\n\u001b[32m    341\u001b[39m         backend_registry = matplotlib.backends.registry.backend_registry\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# ---- (Run this first) ----\n",
    "# import libraries\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, mean_absolute_error, mean_squared_error, r2_score\n",
    "#rom sklearn.neural_network import MLPClassifier\n",
    "#from sklearn.linear_model import Perceptron, LinearRegression\n",
    "#from sklearn import datasets\n",
    "#from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# letting plots appear inline\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a002f",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1 Theory questions\n",
    "\n",
    "Answer **in text** below each question. (1-3 lines per answer)\n",
    "\n",
    "#### 1. What is **supervised learning**? \n",
    "\n",
    "* Supervised learning uses a dataset with a `target`-column.\n",
    "* A dataset with a `target`-column is considered \"labeled\" data.\n",
    "* The `target`-column is the expected output.\n",
    "* The other columns are called `features`.\n",
    "* Given the `features` as input, the model is expected to produce the `target` as output.\n",
    "\n",
    "#### 2. Define **classification**. Give one example.\n",
    "\n",
    "* Classification is the method of grouping together data into distinct groups.\n",
    "* An example of classification is to group players in a role-playing game like: \n",
    "    - \"How often do they login?\" Options: [\"Daily\", \"Weekly\", \"Monthly\"].\n",
    "    - \"Did they spend money?\" Options: [\"Yes\", \"No\"] (binary classification)\n",
    "\n",
    "#### 3. Define **regression**. Give one example.\n",
    "\n",
    "* Regression is the method of approximating the function which gives the best fit to given data.\n",
    "* An example of regression is using a linear function v = ax + b to approximate the relationship between input voltage and output temperature in a thermometer.\n",
    "\n",
    "#### 4. Compare the **difference** between classification and regression?\n",
    "\n",
    "* A classification-function gives categorical output. Example: [\"Male\", \"Female\"], [\"Yes\", \"No\"], etc.\n",
    "* A regression-function gives a numerical output (continuous/floating point or discrete/integer value) over some kind of range. Examples: age in [0-99], temperature in [0, 273], change in [0, 1.0].\n",
    "\n",
    "#### 5. What is a **confusion matrix** used for and how does it help evaluate the performance of a classification model?\n",
    "\n",
    "The confusion matrix shows clearly where the model is correct or where it misclassifies. A perfect model gets a full score, only with values in the diagonal cells and the rest of cells have zero-values. Where the model makes mistakes will be counted in each cell.\n",
    "\n",
    "<div align=\"center\"><img src=\"./images/confusion-matrix.png\" width=300></div>\n",
    "\n",
    "<p align=\"center\"><i>Figure: Confusion matrix shows model predicted wrongly `versicolor` 2 times, when it should have predicted the target: `virginica`.</i></p>\n",
    "\n",
    "#### 6. Why do we **preprocess** data before training? Name **two** techniques.\n",
    "\n",
    "* Binarization - converts binary values to 0 or 1\n",
    "* Mean removal / subtraction - shifts the data by subtracting the mean, and the mean now becomes 0.\n",
    "* Scaling - Adjusts the data to a specific range, for example normalization to the range [0, 1.0]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497428b",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2 Preprocessing & Label Encoding\n",
    "\n",
    "In this task, you are going to practice: scaling, normalization, and label encoding.\n",
    "\n",
    "Here are the sub-tasks:\n",
    "\n",
    "0. Create a small numeric dataset (already provided).\n",
    "1. Apply **StandardScaler** and **MinMaxScaler**. Compare.\n",
    "2. Apply **Normalizer**. Compare.\n",
    "3. Encode simple text labels to numbers with **LabelEncoder**.\n",
    "4. Answer two questions. \n",
    "\n",
    "(HINT: Print small tables. Plot simple histograms to see changes.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4299b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat1  feat2\n",
       "0    1.0   10.0\n",
       "1    2.0   20.0\n",
       "2    3.0   30.0\n",
       "3    4.0   40.0\n",
       "4    5.0   50.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "\n",
    "# --- Task 2.0 Use the provided small dataset below for the following tasks:\n",
    "X = np.array([[1, 10],\n",
    "              [2, 20],\n",
    "              [3, 30],\n",
    "              [4, 40],\n",
    "              [5, 50]], dtype=float)\n",
    "\n",
    "data = DataFrame(X, columns=[\"feat1\",\"feat2\"])\n",
    "print(\"Original data:\")\n",
    "display(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d77dfa0",
   "metadata": {},
   "source": [
    "#### Task 2.1 StandardScaler\n",
    "\n",
    "\n",
    "For every feature (column) the `StandardScaler` computes:\n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\mu}{\\sigma}\n",
    "$$\n",
    "\n",
    "where ùúá is the average and ùúé is the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a5962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.41421356, -1.41421356],\n",
       "       [-0.70710678, -0.70710678],\n",
       "       [ 0.        ,  0.        ],\n",
       "       [ 0.70710678,  0.70710678],\n",
       "       [ 1.41421356,  1.41421356]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard = DataFrame(data)\n",
    "standard = StandardScaler().fit_transform(data)\n",
    "\n",
    "standard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc5caa1",
   "metadata": {},
   "source": [
    "#### Task 2.1 MinMaxScaler\n",
    "\n",
    "For every feature (column) the `MinMaxScaler` computes:\n",
    "$$\n",
    "x' = \\frac{x - x_{\\min}}{x_{\\max} - x_{\\min}}\n",
    "$$\n",
    "\n",
    "where *x_min* is the lowest value in and column and *x_max* is the highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c629bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  ],\n",
       "       [0.25, 0.25],\n",
       "       [0.5 , 0.5 ],\n",
       "       [0.75, 0.75],\n",
       "       [1.  , 1.  ]])"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "minmax = DataFrame(data)\n",
    "minmax = MinMaxScaler().fit_transform(data)\n",
    "\n",
    "minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f207ce55",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 2.2: Normalizer (row-wise to unit norm):\n",
    "\n",
    "For each row **Normalizer** divides the row by the norm/magnitude:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}' = \\frac{\\mathbf{x}}{\\|\\mathbf{x}\\|}\n",
    "$$\n",
    "\n",
    "where the norm/magnitude is given by:\n",
    "\n",
    "$$\n",
    "\\|\\mathbf{x}\\| = \\sqrt{x_1^2 + x_2^2 + \\dots + x_n^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9c08a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09950372, 0.99503719],\n",
       "       [0.09950372, 0.99503719],\n",
       "       [0.09950372, 0.99503719],\n",
       "       [0.09950372, 0.99503719],\n",
       "       [0.09950372, 0.99503719]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "norm = DataFrame(data)\n",
    "norm = Normalizer().fit_transform(data)\n",
    "\n",
    "norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50879734",
   "metadata": {},
   "source": [
    "\n",
    "#### Task 2.3: Label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e6480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5.]), array([10., 20., 30., 40., 50.]))"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#     (tips: want to know the encoding mapping?\n",
    "#      Try \"list(enc.classes_)\", where enc is the LabelEncoder object)\n",
    "\n",
    "LabelEncoder().fit(data[\"feat1\"]).classes_,\\\n",
    "LabelEncoder().fit(data[\"feat2\"]).classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9674a399",
   "metadata": {},
   "source": [
    "\n",
    "##### Task 2.4: Questions (answer **in text** as commments below each question)\n",
    "\n",
    "**Q1: When would you prefer StandardScaler vs MinMaxScaler vs Normalizer? Why? Explain briefly.**\n",
    "\n",
    "* StandardScaler - Scales by column, to a normal distribution. Works well when working with statistical data.\n",
    "* MinMaxScaler - Scales by column, to the range [0, 1], while still possible to compare rows.\n",
    "* Normalizer - Scales by row. Now all iformation about scale between rows is lost. Only direction of each row vector can be compared. Useful for some situations where scale is irrelevant and only direction matters.\n",
    "\n",
    "**Q2: Create a small histogram for one feature before and after scaling. Any differences you notice?**\n",
    "\n",
    "For *standard*- and *minmax*-normalization the main difference is that before the normalization the different features were in different buckes in the histogram. After normalization both feat1 and feat2 are evenly distributed in all histogram-buckets. *norm*-normalization makes sure all values within a single feature/column land in the same histogram-bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71981e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cbfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(standard)\n",
    "plt.show()\n",
    "plt.hist(minmax)\n",
    "plt.show()\n",
    "plt.hist(norm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef0951",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3 Perceptron on a simple problem\n",
    "\n",
    "We use **Perceptron** for a binary task (a \"OR gate\" data).\n",
    "\n",
    "**Steps:**\n",
    "0. Build small binary dataset `X_or`, `y_or`.\n",
    "1. Train `Perceptron()` with default params.\n",
    "2. Print predictions for all inputs.\n",
    "3. Try different `max_iter` and `eta0` (learning rate).\n",
    "4. Answer one question.\n",
    "\n",
    "(Tip: Keep it simple. Focus on input ‚Üí output mapping.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290f1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array\n",
    "\n",
    "# --- Task 3.0: Data (OR problem: output is 1 except when both inputs are 0)\n",
    "X_or = array([[0,0],[0,1],[1,0],[1,1]], dtype=float)\n",
    "y_or = array([0,1,1,1])\n",
    "\n",
    "\n",
    "# --- Task 3.1: Train Perceptron \n",
    "#     (Hint: use Preceptron() from sklearn.linear_model; then fit(X_or, y_or);\n",
    "#            use default params first, then try changing max_iter and eta0)\n",
    "from sklearn.linear_model import Perceptron\n",
    "perceptron = Perceptron(max_iter=10, eta0=0.5, random_state=42)\n",
    "perceptron.fit(X_or, y_or)\n",
    "\n",
    "# --- Task 3.2: Predict\n",
    "#      (Hint: use clf_perc.predict([x]) for each x in X_or, \n",
    "#             where clf_perc is the trained model, replce clf_perc with your model name)\n",
    "perceptron.predict(X_or)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1f24e2",
   "metadata": {},
   "source": [
    "#### Task 3.3: Change max_iter and/or eta0 and re-train. Do results change?\n",
    "\n",
    "Only during the first iteration - with `max_iter=1` a difference in result is observed. Else no change from the base `max_iter=10` and `eta0=0.5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77857bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- max_iter=1: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.1:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.2:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.3:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.4:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.5:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.6:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.7:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.8:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=0.9:  [1 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=1, eta0=1.0:  [1 1 1 1]\n",
      "--- max_iter=2: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=2, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=3: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=3, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=4: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=4, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=5: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=5, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=6: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=6, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=7: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=7, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=8: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=8, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=9: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=9, eta0=1.0:  [0 1 1 1]\n",
      "--- max_iter=10: -------------------------------------------------------\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.1:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.2:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.3:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.4:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.5:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.6:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.7:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.8:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=0.9:  [0 1 1 1]\n",
      "perceptron.predict(X_or) with max_iter=10, eta0=1.0:  [0 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/Users/jonas/git/github.com/Arxcis/VE3451-KI-og-maskinl-ring/.venv/lib/python3.13/site-packages/sklearn/linear_model/_stochastic_gradient.py:726: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(f\"--- max_iter={i}: -------------------------------------------------------\")\n",
    "    for j in range(1, 11):\n",
    "        perceptron = Perceptron(max_iter=i, eta0=0.1*j, random_state=42)\n",
    "        perceptron.fit(X_or, y_or)\n",
    "        print(f\"perceptron.predict(X_or) with max_iter={i}, eta0={0.1*j:.1f}: \", perceptron.predict(X_or))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35837c",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4 Linear Regression (Single Variable)\n",
    "\n",
    "We fit a **Linear Regression** model to a 1D dataset.\n",
    "\n",
    "**Steps:**\n",
    "1. Generate synthetic data: `y = 2.5 * x + noise`.\n",
    "2. Fit `LinearRegression()`.\n",
    "3. Report **MAE**, **MSE**, **R¬≤**.\n",
    "4. Plot data points and the regression line.\n",
    "5. Answer questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba8a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task 4.1: Generate synthetic single variable data: y = 2.5 * x + noise, noise ~ N(0,1), X in [0,10], 40 samples\n",
    "#     (Hint: use linspace to generate x values; use np.random.normal to generate noise)\n",
    "\n",
    "\n",
    "# --- Task 4.2: Fit model \n",
    "#     (Hint: use LinearRegression() from sklearn.linear_model; then fit())\n",
    "\n",
    "\n",
    "# --- Task 4.3: Metrics (MAE, MSE, R¬≤)\n",
    "\n",
    "\n",
    "# --- Task 4.4: Plot data points and the regression line\n",
    "\n",
    "\n",
    "# --- Task 4.5: Questions ---\n",
    "# Q1: Change the slope in data generation to 3.0 and re-run. What happens to R^2? \n",
    "# # -> (your answer):\n",
    "# Q2: Try adding larger noise (e.g., std=3.0). How do MAE/MSE change?\n",
    "#  -> (your answer):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5461e",
   "metadata": {},
   "source": [
    "\n",
    "## Task 5 Using kNN for outlier detection\n",
    "\n",
    "We use Iris data (only two features: sepal length & sepal width).  \n",
    "We mark points with **large average distance** to their **k** nearest neighbors.\n",
    "\n",
    "**Steps:**\n",
    "1. Load Iris. Keep only columns: sepal length, sepal width.\n",
    "2. Fit `NearestNeighbors(n_neighbors=k)`.\n",
    "3. Compute the mean distance for each point to its neighbors.\n",
    "4. Choose a threshold (e.g., top 10% largest distances) ‚Üí mark outliers.\n",
    "5. Plot scatter; mark outliers differently.\n",
    "\n",
    "Start with `k = 5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e641ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task 5.1: Load Iris data (sepal length and width)\n",
    "#     (Hint: use datasets.load_iris() from sklearn; then use data[:, :2] to get first two features)\n",
    "\n",
    "\n",
    "# --- Task 5.2: Fit NearestNeighbors\n",
    "#     (Hint: use NearestNeighbors(n_neighbors=k) from sklearn.neighbors)\n",
    "\n",
    "\n",
    "# --- Task 5.3: Mean distance to neighbors\n",
    "#     (Hint: use nn.kneighbors(X_iris) to get distances and indices of neighbors, then compute mean distance)\n",
    "\n",
    "\n",
    "# --- Task 5.4: Threshold= top 10%, and find outliers\n",
    "#     (Hint: use np.percentile to get the threshold)\n",
    "\n",
    "\n",
    "# --- Task 5.5: Plot, mark outliers differently, e.g., with 'x'/'*'/'^' marker, different color, etc.\n",
    "\n",
    "\n",
    "# --- Questions ---\n",
    "# 1: Change k to 2 and 10. How does the outlier set change?\n",
    "#  -> (your answer):\n",
    "# 2: Try a stricter threshold (e.g., top 5%). What happens?\n",
    "#  -> (your answer):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f85a4",
   "metadata": {},
   "source": [
    "\n",
    "## (Final task) Task 6 End-to-End Classification Pipeline\n",
    "\n",
    "We build a complete supervised learning pipeline using **Digits** data:\n",
    "- **Aim:** Classify hand-written digits (\"0\"‚Äì\"9\").\n",
    "- **Model:** `MLPClassifier`, a simple neural network.\n",
    "- **Outputs:** Accuracy and **confusion matrix**.\n",
    "\n",
    "**Steps:**\n",
    "1. Load data: `datasets.load_digits()`.\n",
    "2. Train/validation split: 80% / 20%.\n",
    "3. Scale features with `StandardScaler()`.\n",
    "4. Train `MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=0)`.\n",
    "5. Evaluate on validation set. Print accuracy.\n",
    "6. Show the **confusion matrix** with `ConfusionMatrixDisplay`.\n",
    "7. Write 3‚Äì5 lines: What mistakes are most common? Why?\n",
    "\n",
    "**Tips:**\n",
    "- If training warns about convergence, **increase** `max_iter`.\n",
    "- Use a **small network** to keep runtime short.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c4447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Task 6.1: Load digits\n",
    "#     (Hint: use datasets.load_digits() from sklearn)\n",
    "\n",
    "\n",
    "# --- Task 6.2: Split data into train and validation \n",
    "#     (Hint: use train_test_split from sklearn.model_selection)\n",
    "\n",
    "\n",
    "# --- Task 6.3: Scaling (NOTE: fit on train only!!)\n",
    "\n",
    "\n",
    "\n",
    "# --- Task 6.4: Train a MLPClassifier\n",
    "#     (Hint: use MLPClassifier from sklearn.neural_network)\n",
    "\n",
    "\n",
    "# --- Task 6.5: Evaluate.  Print accuracy.\n",
    "#    (Hint: use mlp.score(), where mlp is your trained model)\n",
    "\n",
    "\n",
    "# --- Task 6.6: Confusion matrix\n",
    "#    (Hint: use confusion_matrix and ConfusionMatrixDisplay from sklearn.metrics)\n",
    "\n",
    "\n",
    "# --- Task 6.7: Questions ---\n",
    "# 1: In 3‚Äì5 lines: describe the main error types you see and a possible reason (e.g., similar shapes).\n",
    "#  -> (your answer):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10a27f",
   "metadata": {},
   "source": [
    "## (Optional) Any refection or additional notes you want to add here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f3f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
