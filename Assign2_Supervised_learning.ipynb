{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f369f0a",
   "metadata": {},
   "source": [
    "\n",
    "# Assignments #2 Supervised Learning  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56e82866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Done!\n"
     ]
    }
   ],
   "source": [
    "# ---- (Run this first) ----\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron, LinearRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# letting plots appear inline\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"All Done!\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a002f",
   "metadata": {},
   "source": [
    "\n",
    "## Task 1 Theory questions\n",
    "\n",
    "Answer **in text** below each question. (1-3 lines per answer)\n",
    "\n",
    "1. What is **supervised learning**? \n",
    "2. Define **classification**. Give one example.  \n",
    "3. Define **regression**. Give one example.\n",
    "4. Compare the **difference** between classification and regression? \n",
    "5. What is a **confusion matrix** used for and how does it help evaluate the performance of a classification model?\n",
    "6. Why do we **preprocess** data before training? Name **two** techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6497428b",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2 Preprocessing & Label Encoding\n",
    "\n",
    "In this task, you are going to practice: scaling, normalization, and label encoding.\n",
    "\n",
    "Here are the sub-tasks:\n",
    "\n",
    "0. Create a small numeric dataset (already provided).\n",
    "1. Apply **StandardScaler** and **MinMaxScaler**. Compare.\n",
    "2. Apply **Normalizer**. Compare.\n",
    "3. Encode simple text labels to numbers with **LabelEncoder**.\n",
    "4. Answer two questions. \n",
    "\n",
    "(HINT: Print small tables. Plot simple histograms to see changes.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4299b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat1</th>\n",
       "      <th>feat2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat1  feat2\n",
       "0    1.0   10.0\n",
       "1    2.0   20.0\n",
       "2    3.0   30.0\n",
       "3    4.0   40.0\n",
       "4    5.0   50.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- Task 2.0 Use the provided small dataset below for the following tasks:\n",
    "X = np.array([[1, 10],\n",
    "              [2, 20],\n",
    "              [3, 30],\n",
    "              [4, 40],\n",
    "              [5, 50]], dtype=float)\n",
    "df = pd.DataFrame(X, columns=[\"feat1\",\"feat2\"])\n",
    "print(\"Original data:\")\n",
    "display(df)\n",
    "\n",
    "# --- Task 2.1 StandardScaler and MinMaxScaler:\n",
    "\n",
    "\n",
    "# --- Task 2.2: Normalizer (row-wise to unit norm):\n",
    "\n",
    "\n",
    "# --- Task 2.3: Label Encoding\n",
    "#     (tips: want to know the encoding mapping?\n",
    "#      Try \"list(enc.classes_)\", where enc is the LabelEncoder object)\n",
    "\n",
    "\n",
    "# --- Task 2.4: Questions (answer **in text** as commments below each question)\n",
    "# Q1: When would you prefer StandardScaler vs MinMaxScaler vs Normalizer? Why? Explain briefly.\n",
    "#  -> (your answer):  \n",
    "# Q2: Create a small histogram for one feature before and after scaling. Any differences you notice?\n",
    "#  -> (your answer): \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ef0951",
   "metadata": {},
   "source": [
    "\n",
    "## Task 3 Perceptron on a simple problem\n",
    "\n",
    "We use **Perceptron** for a binary task (a \"OR gate\" data).\n",
    "\n",
    "**Steps:**\n",
    "0. Build small binary dataset `X_or`, `y_or`.\n",
    "1. Train `Perceptron()` with default params.\n",
    "2. Print predictions for all inputs.\n",
    "3. Try different `max_iter` and `eta0` (learning rate).\n",
    "4. Answer one question.\n",
    "\n",
    "(Tip: Keep it simple. Focus on input → output mapping.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e290f1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task 3.0: Data (OR problem: output is 1 except when both inputs are 0)\n",
    "X_or = np.array([[0,0],[0,1],[1,0],[1,1]], dtype=float)\n",
    "y_or = np.array([0,1,1,1])\n",
    "\n",
    "\n",
    "# --- Task 3.1: Train Perceptron \n",
    "#     (Hint: use Preceptron() from sklearn.linear_model; then fit(X_or, y_or);\n",
    "#            use default params first, then try changing max_iter and eta0)\n",
    "\n",
    "\n",
    "# --- Task 3.2: Predict\n",
    "#      (Hint: use clf_perc.predict([x]) for each x in X_or, \n",
    "#             where clf_perc is the trained model, replce clf_perc with your model name)\n",
    "\n",
    "\n",
    "# --- Task 3.3: Questions ---\n",
    "# Q1: Change max_iter and/or eta0 and re-train. Do results change?\n",
    "#  -> (your answer):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35837c",
   "metadata": {},
   "source": [
    "\n",
    "## Task 4 Linear Regression (Single Variable)\n",
    "\n",
    "We fit a **Linear Regression** model to a 1D dataset.\n",
    "\n",
    "**Steps:**\n",
    "1. Generate synthetic data: `y = 2.5 * x + noise`.\n",
    "2. Fit `LinearRegression()`.\n",
    "3. Report **MAE**, **MSE**, **R²**.\n",
    "4. Plot data points and the regression line.\n",
    "5. Answer questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ba8a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task 4.1: Generate synthetic single variable data: y = 2.5 * x + noise, noise ~ N(0,1), X in [0,10], 40 samples\n",
    "#     (Hint: use linspace to generate x values; use np.random.normal to generate noise)\n",
    "\n",
    "\n",
    "# --- Task 4.2: Fit model \n",
    "#     (Hint: use LinearRegression() from sklearn.linear_model; then fit())\n",
    "\n",
    "\n",
    "# --- Task 4.3: Metrics (MAE, MSE, R²)\n",
    "\n",
    "\n",
    "# --- Task 4.4: Plot data points and the regression line\n",
    "\n",
    "\n",
    "# --- Task 4.5: Questions ---\n",
    "# Q1: Change the slope in data generation to 3.0 and re-run. What happens to R^2? \n",
    "# # -> (your answer):\n",
    "# Q2: Try adding larger noise (e.g., std=3.0). How do MAE/MSE change?\n",
    "#  -> (your answer):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc5461e",
   "metadata": {},
   "source": [
    "\n",
    "## Task 5 Using kNN for outlier detection\n",
    "\n",
    "We use Iris data (only two features: sepal length & sepal width).  \n",
    "We mark points with **large average distance** to their **k** nearest neighbors.\n",
    "\n",
    "**Steps:**\n",
    "1. Load Iris. Keep only columns: sepal length, sepal width.\n",
    "2. Fit `NearestNeighbors(n_neighbors=k)`.\n",
    "3. Compute the mean distance for each point to its neighbors.\n",
    "4. Choose a threshold (e.g., top 10% largest distances) → mark outliers.\n",
    "5. Plot scatter; mark outliers differently.\n",
    "\n",
    "Start with `k = 5`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41e641ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Task 5.1: Load Iris data (sepal length and width)\n",
    "#     (Hint: use datasets.load_iris() from sklearn; then use data[:, :2] to get first two features)\n",
    "\n",
    "\n",
    "# --- Task 5.2: Fit NearestNeighbors\n",
    "#     (Hint: use NearestNeighbors(n_neighbors=k) from sklearn.neighbors)\n",
    "\n",
    "\n",
    "# --- Task 5.3: Mean distance to neighbors\n",
    "#     (Hint: use nn.kneighbors(X_iris) to get distances and indices of neighbors, then compute mean distance)\n",
    "\n",
    "\n",
    "# --- Task 5.4: Threshold= top 10%, and find outliers\n",
    "#     (Hint: use np.percentile to get the threshold)\n",
    "\n",
    "\n",
    "# --- Task 5.5: Plot, mark outliers differently, e.g., with 'x'/'*'/'^' marker, different color, etc.\n",
    "\n",
    "\n",
    "# --- Questions ---\n",
    "# 1: Change k to 2 and 10. How does the outlier set change?\n",
    "#  -> (your answer):\n",
    "# 2: Try a stricter threshold (e.g., top 5%). What happens?\n",
    "#  -> (your answer):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f85a4",
   "metadata": {},
   "source": [
    "\n",
    "## (Final task) Task 6 End-to-End Classification Pipeline\n",
    "\n",
    "We build a complete supervised learning pipeline using **Digits** data:\n",
    "- **Aim:** Classify hand-written digits (\"0\"–\"9\").\n",
    "- **Model:** `MLPClassifier`, a simple neural network.\n",
    "- **Outputs:** Accuracy and **confusion matrix**.\n",
    "\n",
    "**Steps:**\n",
    "1. Load data: `datasets.load_digits()`.\n",
    "2. Train/validation split: 80% / 20%.\n",
    "3. Scale features with `StandardScaler()`.\n",
    "4. Train `MLPClassifier(hidden_layer_sizes=(50,), max_iter=300, random_state=0)`.\n",
    "5. Evaluate on validation set. Print accuracy.\n",
    "6. Show the **confusion matrix** with `ConfusionMatrixDisplay`.\n",
    "7. Write 3–5 lines: What mistakes are most common? Why?\n",
    "\n",
    "**Tips:**\n",
    "- If training warns about convergence, **increase** `max_iter`.\n",
    "- Use a **small network** to keep runtime short.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10c4447d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Task 6.1: Load digits\n",
    "#     (Hint: use datasets.load_digits() from sklearn)\n",
    "\n",
    "\n",
    "# --- Task 6.2: Split data into train and validation \n",
    "#     (Hint: use train_test_split from sklearn.model_selection)\n",
    "\n",
    "\n",
    "# --- Task 6.3: Scaling (NOTE: fit on train only!!)\n",
    "\n",
    "\n",
    "\n",
    "# --- Task 6.4: Train a MLPClassifier\n",
    "#     (Hint: use MLPClassifier from sklearn.neural_network)\n",
    "\n",
    "\n",
    "# --- Task 6.5: Evaluate.  Print accuracy.\n",
    "#    (Hint: use mlp.score(), where mlp is your trained model)\n",
    "\n",
    "\n",
    "# --- Task 6.6: Confusion matrix\n",
    "#    (Hint: use confusion_matrix and ConfusionMatrixDisplay from sklearn.metrics)\n",
    "\n",
    "\n",
    "# --- Task 6.7: Questions ---\n",
    "# 1: In 3–5 lines: describe the main error types you see and a possible reason (e.g., similar shapes).\n",
    "#  -> (your answer):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e10a27f",
   "metadata": {},
   "source": [
    "## (Optional) Any refection or additional notes you want to add here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f3f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
